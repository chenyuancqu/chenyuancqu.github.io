<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>article title</title>
      <link href="/2024/03/14/article-title/"/>
      <url>/2024/03/14/article-title/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/03/14/energy-efficient-federated-learning-over-wireless-communication-networks/"/>
      <url>/2024/03/14/energy-efficient-federated-learning-over-wireless-communication-networks/</url>
      
        <content type="html"><![CDATA[<p>背景：</p><p>在未来的无线系统中，由于隐私限制和数据传输的通信资源有限，所有无线设备将其收集的所有数据传输到数据中心是不切实际的，该数据中心可以使用收集的数据来实现数据分析和推断的集中式机器学习算法 [2]-[7]。为此，需要分布式学习框架，以使无线设备能够协作构建共享学习模型，并在本地训练其收集的数据。</p><p>那目前最有前途的分布式学习算法之一是联邦学习框架。在FL中，无线设备可以通过仅将本地学习模型上传到基站 (BS) 而不是共享其全部训练数据来协同执行学习任务 [27]。</p><p>要通过无线网络实现FL，无线设备必须通过无线链路 [29] 传输其本地训练结果，这可能会由于有限的无线资源 (例如时间和带宽) 而影响FL的性能。此外，无线设备的能量有限是部署FL的关键挑战。实际上，由于这些资源限制，有必要优化FL实施的能源效率。</p><p><strong>本文的主要贡献是针对无线通信网络上的FL的新型节能计算和传输资源分配方案。我们的主要贡献包括:</strong></p><ul><li>我们研究了在无线通信网络上FL算法的性能，在这种情况下，每个用户在给定的学习精度下本地计算其FL模型，并且BS向所有用户广播聚合的FL模型。对于所考虑的FL算法，我们首先推导收敛速度。</li><li>我们制定了一个联合计算和传输优化问题，旨在最大程度地减少本地计算和无线传输的总能耗。为了解决这个问题，提出了一种低复杂度的迭代算法。在该算法的每个步骤中，我们都针对时间分配，带宽分配，功率控制，计算频率和学习精度得出了新的封闭形式解决方案。</li><li>为了获得总能量最小化问题的可行解，我们构造了FL完成时间最小化问题。我们从理论上证明了完成时间是学习精度的凸函数。基于这一理论发现，我们提出了一种基于二分的算法，以获得FL完成时间最小化的最优解。</li><li>为了获得总能量最小化问题的可行解，我们构造了FL完成时间最小化问题。我们从理论上证明了完成时间是学习精度的凸函数。基于这一理论发现，我们提出了一种基于二分的算法，以获得FL完成时间最小化的最优解。</li></ul><p>![image-20240314142452938](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314142452938.png)</p><p>1、系统模型</p><p>这是一个蜂窝网络，该网络由一个服务于K个用户的BS组成，每个用户K都有一个带有DK数据样本的本地数据集DK。BS和所有用户通过无线网络协作执行联邦学习算法以进行数据分析和推断。最后呢，由每个用户的数据集训练的FL模型称为本地FL模型，而由BS使用来自所有用户的本地FL模型输入生成的FL模型称为全局FL模型。</p><p>（本地FL模型和全局FL模型的区别？）</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/03/14/cooperative-computation-offloading-in-blockchain-based-vec/"/>
      <url>/2024/03/14/cooperative-computation-offloading-in-blockchain-based-vec/</url>
      
        <content type="html"><![CDATA[<h1 id="1、文章概述（泛读）"><a href="#1、文章概述（泛读）" class="headerlink" title="1、文章概述（泛读）"></a><strong>1、文章概述（泛读）</strong></h1><h2 id="1-1、文章信息"><a href="#1-1、文章信息" class="headerlink" title="1.1、文章信息"></a><strong>1.1、文章信息</strong></h2><p>IEEE TRANSACTIONS ON INTELLIGENT VEHICLES CCF-B</p><h2 id="1-2、文章介绍"><a href="#1-2、文章介绍" class="headerlink" title="1.2、文章介绍"></a><strong>1.2、文章介绍</strong></h2><p>题目：基于区块链的车辆边缘计算网络中的协同计算卸载</p><p>背景：多路边缘计算（multiaccess edge computing）——将计算和存储能力迁移到网络的边缘节点上（edge nodes）</p><p>大概思想就是通过MEC发送的全局信息将部分任务卸载到相邻车辆以减少MEC压力，减少计算资源闲置造成的浪费。如下图所示：</p><p>![image-20240314143533995](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143533995.png)</p><p>存在问题：</p><ul><li>没有为车辆开发出方法来准确<strong>确定</strong>计算能力和服务提供商的轨迹，以用于卸载计算卸载</li><li>卸载中，传输安全性和车辆隐私难以保障</li></ul><p>所以，在这种情况下区块链技术（一种去中心化的数据存储技术）引起了车辆网络的极大关注，他的特点是分布式处理、多方共识和防篡改功能。</p><p>具体来说，前文所提到的安全挑战，通过区块链技术可以完美解决。</p><p>服务器车辆：可以通过协作计算卸载向用户车辆提供计算服务</p><p>作者引入资源丰富的车辆作为边缘服务器面临两个挑战：</p><ul><li>服务器车辆的可信信息共享</li><li>任务卸载到服务器车辆和路边服务器的策略评估</li></ul><p>随后提出了一种新颖的基于区块链的车载MEC网络数据共享架构</p><p><strong>本文的主要贡献如下：</strong></p><ul><li>提出了一种用户车辆与服务器车辆之间的安全信息共享机制以及基于区块链技术的车辆协同计算方法，以确保安全和准确信息获取</li><li>在基于区块链的数据共享架构中，提出了一种结合了服务证明和PBFT的共识机制，用来实现MEC网络之间的数据同步并防止恶意攻击</li><li>为了帮助用户车辆做出正确的计算卸载决策，提出了一个卸载博弈模型的合作计算卸载场景</li></ul><h1 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a><strong>2、相关工作</strong></h1><ol><li>方法：云辅助车载MEC计算卸载和资源分配问题（卸载任务可以在路边MEC服务器上 或 使用路边单元卸载到云服务器上）</li><li>在变化信道状态和可用带宽不稳定环境中建模任务下载，最小化能量消耗、分配带宽及传输延迟（采用基于深度强化学习的自适应计算卸载方法来解决这个问题）</li><li>联合建模车辆卸载和路边MEC服务器卸载均衡，提出一种服务器选择和卸载的联合优化算法</li><li>在作者前述工作中， 提出了一个用于大量车辆的计算卸载游戏，减少路边MEC服务器的计算负担，设计了一个分布式最佳响应办法，保证了车辆卸载策略收敛的纳什均衡</li></ol><h1 id="3、基于区块链的数据共享"><a href="#3、基于区块链的数据共享" class="headerlink" title="3、基于区块链的数据共享"></a><strong>3、基于区块链的数据共享</strong></h1><h2 id="3-1、方案概述"><a href="#3-1、方案概述" class="headerlink" title="3.1、方案概述"></a><strong>3.1、方案概述</strong></h2><p>MEC服务器利用区块链实现数据共享和同步，在此场景下，为了扩大服务器车辆的服务容量传输范围，放置恶意节点攻击，采用区块链技术将闲置服务器车辆的信息共享给用户车辆，为用户车辆提供资源。</p><h2 id="3-2、基于安全数据共享方案的协作计算卸载"><a href="#3-2、基于安全数据共享方案的协作计算卸载" class="headerlink" title="3.2、基于安全数据共享方案的协作计算卸载"></a>3.2、基于安全数据共享方案的协作计算卸载</h2><p>路边MEC服务器收集服务器车辆的信息共享到区块链上，并将此信息广播到覆盖区域内的所有车辆，然后用户车辆根据接收到的邻近服务器车辆和路边MEC服务器的信息做出博弈决策。</p><p>![image-20240314143553736](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143553736.png)</p><p>步骤如下：</p><p>1、服务器车辆将其服务能力上传到路边MEC服务器上。服务器车辆V_j</p><p>![image-20240314143604384](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143604384.png)</p><p>2、路边MEC服务器收集车辆服务能力信息。收到V发来的加密信息后，进行私钥解密并验证后进行存储，存储格式如下：</p><p>![image-20240314143615781](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143615781.png)</p><p>3、MEC服务器向区块链增加服务器车辆的服务能力记录</p><p>![image-20240314143624851](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143624851.png)</p><p>具体过程为：</p><ul><li>广播：MEC收到后，将信息广播给其他MEC</li><li>选择：选择一个有冗余计算能力的MEC节点作为主节点生成区块添加到当前链中</li><li>预准备：每个节点确定自己是否是主节点。如果它是被选中的领导者，它会将生成的区块和验证结果作为预准备消息广播给区块链网络中的其他MEC服务器。</li><li>准备：接收预准备信息后，所有的MEC服务器确定leader身份和区块链信息有效性，然后向网络中广播确认结果</li><li>提交：每个MEC服务器收到其他节点发送的准备消息后，将这些消息沿着自己的验证结果一起决定是否成功生成区块链</li><li>回复：确认每个节点的提交消息并将共识结果发送给 领导者</li><li>存储：主节点接收各MEC服务器共识结果，并将最新的区块发送给系统中的所有MEC服务器进行数据共享和存储</li></ul><p>4、路边MEC服务器向覆盖区域内所有车辆用户发送该区块的服务能力信息</p><p>5、用户车辆基于MEC服务器和相邻服务器车辆的服务能力做出卸载决策</p><p>6、服务器车辆上传正在进行的业务信息，MEC服务器更新服务区块链</p><p>7、用户车辆评估服务的质量，并且MEC服务器基于该评估动态地对服务定价</p><h2 id="3-3、安全性分析"><a href="#3-3、安全性分析" class="headerlink" title="3.3、安全性分析"></a><strong>3.3、安全性分析</strong></h2><p>恶意车辆信息欺骗</p><p>恶意评价用户车辆</p><p>MEC服务器的伪块生成和多数攻击</p><p>MEC服务器的数据篡改</p><h1 id="4、基于博弈论的协作计算卸载"><a href="#4、基于博弈论的协作计算卸载" class="headerlink" title="4、基于博弈论的协作计算卸载"></a><strong>4、基于博弈论的协作计算卸载</strong></h1><p>本文主要问题是如何在基于区块链的车辆边缘计算网络中实现分布式最优卸载决策，为此，提出了一种基于博弈的协同计算卸载算法</p><h2 id="4-1、协同计算卸载模型"><a href="#4-1、协同计算卸载模型" class="headerlink" title="4.1、协同计算卸载模型"></a><strong>4.1、协同计算卸载模型</strong></h2><p>用户将任务代码、输入数据和最后期限发送到MEC服务器或服务器车辆。</p><ul><li>需要卸载的用户车辆V的应用模型表示为三元组：![image-20240314143638925](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143638925.png)</li></ul><p>L代表要卸载的应用输入数据大小</p><p>α 代表计算复杂度——处理应用程序中1位数据所需的CPU周期数</p><p>t  代表最大可容忍执行时间</p><h3 id="4-1-1、通信模型"><a href="#4-1-1、通信模型" class="headerlink" title="4.1.1、通信模型"></a><strong>4.1.1、通信模型</strong></h3><p>用户车辆V_i和MEC服务器之间的卸载请求和返回结果传输速率表示为：</p><p>![image-20240314143659857](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143659857.png)</p><p>W和d分别表示用户车辆和MEC服务器之间的带宽和距离</p><p>N代表高斯白色噪声功率，N取决于带宽，因为在中国V2V和V2I的带宽是恒定为10MHz</p><p>作者考虑使用LTE-V2X实现通信，其通过正交频分复用（OFDM）的多址方法实现数据传输。</p><p>类似的，用户车辆V_i和服务器车辆V_j之间的卸载请求和返回结果传输速率表示为：</p><p>![image-20240314143712164](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143712164.png)</p><p>P代表服务器车辆的传输速率</p><h3 id="4-1-2、计算延迟模型"><a href="#4-1-2、计算延迟模型" class="headerlink" title="4.1.2、计算延迟模型"></a><strong>4.1.2、计算延迟模型</strong></h3><p>将任务卸载到MEC服务器和服务车辆上的计算延迟可表示为：</p><p>![image-20240314143731161](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143731161.png)</p><p>![image-20240314143737750](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143737750.png)</p><p>基于此，用户车辆可以量化V2M和V2V的效用并决定是否将任务卸载到MEC服务器或服务器车辆</p><h2 id="4-2、协同计算卸载博弈"><a href="#4-2、协同计算卸载博弈" class="headerlink" title="4.2、协同计算卸载博弈"></a><strong>4.2、协同计算卸载博弈</strong></h2><p>计算卸载的博弈模型：</p><p>![image-20240314143754820](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143754820.png)</p><p>N表示MEC服务器覆盖下的所有车辆集合</p><p>p∈[0,1]  是用户车辆v的混合卸载策略，如果p靠近1，vi将会以更大概率将任务卸载到MEC服务器</p><p>u 是v可以从收益函数的博弈中获得的收益</p><p>首先，使用任务执行的延迟表征用户车辆在协同计算卸载中的效用，但在实际中，只要任务延迟不超过其最大可容忍执行时间，用户车辆就可以收益于任务成功执行。</p><p>基于最小化执行延迟也会使用户车辆激烈争夺边缘服务器资源，导致一些等待时间较长的任务超时，因此作者以二次函数的形式构造了值函数，并使用参数动态调节值与延迟曲线：</p><p>![image-20240314143807949](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143807949.png)</p><p>其中，t是V2M或者V2V的卸载总延迟</p><p>如图4看出，当δ较大时任务在较低延迟时到达最大值</p><p>![image-20240314143817889](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143817889.png)</p><p>通过value函数表示不同计算卸载策略的预期效用</p><p>![image-20240314143831376](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143831376.png)</p><h2 id="4-3、分布式计算卸载解决方案"><a href="#4-3、分布式计算卸载解决方案" class="headerlink" title="4.3、分布式计算卸载解决方案"></a><strong>4.3、分布式计算卸载解决方案</strong></h2><p>![image-20240314143841280](/Users/chenyuan/Library/Application Support/typora-user-images/image-20240314143841280.png)</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/03/14/hello-world/"/>
      <url>/2024/03/14/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo generate<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/03/14/bian-yuan-ji-suan-zhong-shi-yong-duo-zhi-neng-ti-drl-jin-xing-de-ji-suan-xie-zai-suan-fa/"/>
      <url>/2024/03/14/bian-yuan-ji-suan-zhong-shi-yong-duo-zhi-neng-ti-drl-jin-xing-de-ji-suan-xie-zai-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="1、文章概述"><a href="#1、文章概述" class="headerlink" title="1、文章概述"></a>1、文章概述</h1><h2 id="1-1、文章信息"><a href="#1-1、文章信息" class="headerlink" title="1.1、文章信息"></a>1.1、文章信息</h2><p>CCF-B ACM Transactions on Sensor Networks</p><h2 id="1-2、文章介绍"><a href="#1-2、文章介绍" class="headerlink" title="1.2、文章介绍"></a>1.2、文章介绍</h2><p>计算卸载决策涉及联合和复杂的资源管理，所以使用部署在物联网设备上的多个深度强化学习代理来指导自己的决策。此外，使用联邦学习以分布式方式训练DRL的agent，旨在使基于DRL的决策实际可行，并进一步降低物联网设备和边缘节点之间的传输成本。文章作者研究了计算卸载优化问题，证明了该问题是一个np-hard问题，然后基于DRL和FL提出了一个卸载算法。</p><p>这种优化算法具备以下优势：有利于通信传输、对动态环境的适应性、不仅在时间段内优化系统而且会考虑长期效益。</p><p>作者使用联邦学习（FL）来进行DRL代理的训练过程，以共同分配通信和计算资源。具体而言，主要贡献有三个方面：</p><ul><li>研究了计算卸载问题，证明其是np-hard问题</li><li>设计了计算卸载和能量分配决策算法；该算法基于联邦学习进行训练，使得每个物联网设备收集的数据在本地分析处理实现了隐私保护</li><li>进行了算法评估，证明与集中式训练方法相比具有有效性</li></ul><p>问题：与集中式训练方法相比是否有更好的速度？</p><h1 id="2、背景"><a href="#2、背景" class="headerlink" title="2、背景"></a>2、背景</h1><h2 id="2-1、深度强化学习"><a href="#2-1、深度强化学习" class="headerlink" title="2.1、深度强化学习"></a>2.1、深度强化学习</h2><p>由于强化学习（RL）技术通常应用于小数据空间，因此使用RL处理高维数据是困难的。然而，深度强化学习（DRL）通过将深度学习的高维输入与RL相结合解决了这个问题。</p><h2 id="2-2、联邦学习"><a href="#2-2、联邦学习" class="headerlink" title="2.2、联邦学习"></a>2.2、联邦学习</h2><p>由google提出的联邦学习，它允许多个终端设备在本地数据上进行训练，然后只需要将更新上传到云。</p><p>过程：</p><p>1）终端设备从云中下载共享模型，然后根据本地数据训练模型</p><p>2）通过加密传输将更新传输到云中。</p><p>3）云根据来自多个终端设备的更新来集成共享模型。</p><p>由于用户数据在整个过程中始终存储在终端设备本地，因此可以避免大量数据传输到云端，从而减轻数据传输压力，保护数据隐私。</p><p><img src="https://img-blog.csdnimg.cn/6ce1bc13e57344079982f175354bd80c.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>但在实际应用中，仍然存在一些问题。一方面，样本数据将以极不均匀的方式分布在大量终端设备中。另一方面，终端设备的传输速度较慢，特别是数据上传速度会限制整体性能。</p><p>为了解决这些问题，谷歌开发了一种算法联邦平均，以减少训练深度神经网络时的网络要求，并通过使用随机旋转和量化来压缩更新，以减少传输的数据量。此外，设计了一种联邦优化算法来优化高维稀疏凸模型。</p><h2 id="2-3、边缘计算"><a href="#2-3、边缘计算" class="headerlink" title="2.3、边缘计算"></a>2.3、边缘计算</h2><p>略</p><h1 id="3、系统模型"><a href="#3、系统模型" class="headerlink" title="3、系统模型"></a>3、系统模型</h1><h2 id="3-1、概述"><a href="#3-1、概述" class="headerlink" title="3.1、概述"></a>3.1、概述</h2><p><img src="https://img-blog.csdnimg.cn/70be68f73aae4dfbab9d8551117aae19.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>IOT设备生成的计算任务被建模为</p><p><img src="https://img-blog.csdnimg.cn/ed56f3715cbb490ca64aed6a0a3dc127.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>μ代表卸载任务所需的传输数据大小</p><p>v代表处理任务所需的CPU周期数</p><h2 id="3-2、系统模型描述"><a href="#3-2、系统模型描述" class="headerlink" title="3.2、系统模型描述"></a>3.2、系统模型描述</h2><h3 id="3-2-1、系统模型体系结构"><a href="#3-2-1、系统模型体系结构" class="headerlink" title="3.2.1、系统模型体系结构"></a>3.2.1、系统模型体系结构</h3><p><img src="https://img-blog.csdnimg.cn/dfbf3b4423f44084b853043a380091db.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>IOT设备需要在epoch i 中做出一个动作集合</p><p><img src="https://img-blog.csdnimg.cn/8db2317ac88c4a0284348835f8caf6e9.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>其中C代表卸载决策，具体由0、1、2……N（0代表本地执行，1-N代表在编号为n的EN上执行）</p><p>e代表分配的能量单位数量，其影响CPU频率和IOT设备的数据传输速率</p><h3 id="3-2-2、本地执行"><a href="#3-2-2、本地执行" class="headerlink" title="3.2.2、本地执行"></a>3.2.2、本地执行</h3><p>本地执行的时间约束：</p><p><img src="https://img-blog.csdnimg.cn/0043be89c91943218b7fd66caf9e94f2.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>后者是执行一个任务的速率</p><p>本地执行的时间消耗如下：</p><p><img src="https://img-blog.csdnimg.cn/8fdbc56fab594e7981057530de062a71.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h3 id="3-2-3、EN上执行"><a href="#3-2-3、EN上执行" class="headerlink" title="3.2.3、EN上执行"></a>3.2.3、EN上执行</h3><ul><li>另Si代表epoch i 开始的IOT和EN之间的连接状态</li></ul><p><img src="https://img-blog.csdnimg.cn/3340d7774f6347ad99d07ee873e50cb7.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><ul><li><p>改变EN延迟表示为σ</p></li><li><p>无线信道传输速率：</p></li></ul><p><img src="https://img-blog.csdnimg.cn/7cdb55e56ade4ce9a9b2cd9e28295562.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>其中，P表示IOT设备u和的传输速率</p><ul><li>数据传输的时间消耗：</li></ul><p><img src="https://img-blog.csdnimg.cn/eaa72f59315741be88e051afec6a30c3.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>另外，作者根据其他论文发现保持传输速率恒定可以实现最小传输时间，所以最小传输时间求解为：</p><p><img src="https://img-blog.csdnimg.cn/ed28b33a40374731961766f246ef9abb.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><ul><li>任务在EN上的执行延迟：</li></ul><p><img src="https://img-blog.csdnimg.cn/694cd076099f4542a01dcefdb2e44d33.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><ul><li>为避免实际操作中EN资源的额外使用，设置的额外成本</li></ul><p><img src="https://img-blog.csdnimg.cn/eeff601015d14ed285a4246f67a8f8eb.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h3 id="3-2-4、更新系统模型参数"><a href="#3-2-4、更新系统模型参数" class="headerlink" title="3.2.4、更新系统模型参数"></a>3.2.4、更新系统模型参数</h3><p>任务执行延迟可以表示如下：</p><p><img src="https://img-blog.csdnimg.cn/33b1c84b758d43f3b9d10789772d184b.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><ul><li>考虑并非所有任务生成后都能被立即执行，因此使用如下来表示在epoch i 下的排队延迟：</li></ul><p><img src="https://img-blog.csdnimg.cn/dbc56a2a6263472cb633cd53da480b00.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h1 id="4、联邦学习协调下的策略训练"><a href="#4、联邦学习协调下的策略训练" class="headerlink" title="4、联邦学习协调下的策略训练"></a>4、联邦学习协调下的策略训练</h1><h2 id="4-1、问题建模"><a href="#4-1、问题建模" class="headerlink" title="4.1、问题建模"></a>4.1、问题建模</h2><p>使用Xi代表epoch i中的IoT设备的网络环境，IoT设备在epoch的初始时段做出卸载决策并决定分配的能量单元数量。</p><p>策略定义为Φ，长期效用定义为：</p><p><img src="https://img-blog.csdnimg.cn/a126336b699142718ada478cf4179414.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>u(.)代表在epoch i中的短期效用，该优化策略可以根据目标进行个性化。例如，如果低延迟是系统中最重要的指标，则可以调整任务执行延迟di和任务排队延迟Pi的权重以改变整个效用中的延迟比例。</p><h2 id="4-2、复杂性分析"><a href="#4-2、复杂性分析" class="headerlink" title="4.2、复杂性分析"></a>4.2、复杂性分析</h2><p>略</p><h2 id="4-3、在边缘计算中使用联邦学习的原因"><a href="#4-3、在边缘计算中使用联邦学习的原因" class="headerlink" title="4.3、在边缘计算中使用联邦学习的原因"></a>4.3、在边缘计算中使用联邦学习的原因</h2><p>作者使用DDQN来解决计算卸载中的最大化长期效用问题。但尽管DDQN可以进行高效决策，但会消耗很多计算资源，所以如何训练需要考虑：</p><ul><li>如果agent在EN上训练存在问题：</li></ul><ol><li>IoT设备与EN之间传输数据，增加无线信道传输压力</li><li>传输数据不利于隐私保护</li><li>就算隐私信息可以通过某种方式去除，但会破坏数据完整性，影响训练效果</li></ol><ul><li>如果在本地单独训练存在问题</li></ul><ol><li>训练每个DRL 的 agent花费时间太长</li><li>每个Agent单独训练耗费能量更多</li></ol><p>基于以上原因，作者采用分布式方式训练DRL</p><p><img src="https://img-blog.csdnimg.cn/d328e05114d44233bea88366115571b5.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h2 id="4-4、基于联邦学习的计算卸载DRL训练"><a href="#4-4、基于联邦学习的计算卸载DRL训练" class="headerlink" title="4.4、基于联邦学习的计算卸载DRL训练"></a>4.4、基于联邦学习的计算卸载DRL训练</h2><p>Federated Learning-Based DRL Training about Computation Offloading</p><p><img src="https://img-blog.csdnimg.cn/251a5099ab8c4c6d9d66af8e0eede774.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p><img src="https://img-blog.csdnimg.cn/78ce89ecf1e24a9abffad0fe00773054.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>步骤简述：</p><p>初始化ENs集合N，IoT设备集合D</p><p>随机选取m个IoT设备执行迭代：</p><p>对于设备d执行迭代：</p><p>从关联EN获取DRL代理权重并赋给自身</p><p>获取本地数据并利用其训练agent</p><p>上传更新参数到EN</p><p>对于EN执行迭代：</p><p>接收更新参数进行聚合</p><h2 id="4-5、联邦学习策略理论分析（略）"><a href="#4-5、联邦学习策略理论分析（略）" class="headerlink" title="4.5、联邦学习策略理论分析（略）"></a>4.5、联邦学习策略理论分析（略）</h2><h1 id="5、性能评价"><a href="#5、性能评价" class="headerlink" title="5、性能评价"></a>5、性能评价</h1><h2 id="5-1、实验设置"><a href="#5-1、实验设置" class="headerlink" title="5.1、实验设置"></a>5.1、实验设置</h2><p><img src="https://img-blog.csdnimg.cn/d4d4cf8365264869b3b14c7dcc62e150.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h2 id="5-2、探索概率分析"><a href="#5-2、探索概率分析" class="headerlink" title="5.2、探索概率分析"></a>5.2、探索概率分析</h2><p>经过分析，作者进行了百次实验采集静校正量。</p><h2 id="5-3、任务生成概率分析"><a href="#5-3、任务生成概率分析" class="headerlink" title="5.3、任务生成概率分析"></a>5.3、任务生成概率分析</h2><p>任务生成概率作为一个设置参数被用来做比较，以评判算法在高负载情况下的表现，实验数据表明在任务生成概率很高（0.9）时候算法仍然具有很高的效用值（utility value）</p><h2 id="5-4、能量生成概率分析"><a href="#5-4、能量生成概率分析" class="headerlink" title="5.4、能量生成概率分析"></a>5.4、能量生成概率分析</h2><p>原因：IoT的部署条件差异会导致不同的能量生成概率</p><p>通过实验表明，能量生成概率越高，有越多的任务被分配到EN上执行，也就是说EN会消耗更多的能量，但会获得更高的任务处理能力。</p><h2 id="5-5、IoT设备数量分析"><a href="#5-5、IoT设备数量分析" class="headerlink" title="5.5、IoT设备数量分析"></a>5.5、IoT设备数量分析</h2><p>原因：接入的IoT数量难以确定，所以需要做实验对比不同IoT设备下的实验数据</p><p>结论：</p><ol><li>不同数量IoT设备的早期都呈现上升趋势，后期都趋于稳定</li><li>同时也有不同点： <ol><li>IoT设备较少时，早期效用增长相对缓慢</li><li>所有的效用在后期都会稳定在同一水平，但不同数量的IoT设备会对效用的标准差产生影响，数量越少标准差越大、性能趋于越稳定</li></ol></li><li>早期IoT设备越多，性能越好；但在训练收敛之后，物联网设备越多，性能就越差。原因见论文</li></ol><p>物联网设备越多，训练时的收敛速度越快，即早期性能越好。但经过训练聚合后，不同数量的IoT设备的性能趋于同一水平。</p><h2 id="5-6、能量消耗分析"><a href="#5-6、能量消耗分析" class="headerlink" title="5.6、能量消耗分析"></a>5.6、能量消耗分析</h2><p>基于FL的DRL训练和集中式DRL训练的能耗都高于贪婪策略。原因可能是使用更多的能量减少任务丢弃的数量和任务执行延迟。</p><p>提出的算法可能导致更高的能量消耗，这可能是由于用于本地执行或数据传输的更高功率。在这种情况下，尽管能量消耗可能处于高水平，但是在时间延迟、任务丢弃的数量等方面有所改善。</p><h2 id="5-7、系统模型中关键指标比较"><a href="#5-7、系统模型中关键指标比较" class="headerlink" title="5.7、系统模型中关键指标比较"></a>5.7、系统模型中关键指标比较</h2><h3 id="5-7-1、任务执行延迟"><a href="#5-7-1、任务执行延迟" class="headerlink" title="5.7.1、任务执行延迟"></a>5.7.1、任务执行延迟</h3><p>Def：任务从离开任务队列到完成的时间，包含建立连接时间+传输任务数据时间+执行任务时间</p><p><img src="https://img-blog.csdnimg.cn/481931f0b2774cd9b8db377d0bf9e4c8.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h3 id="5-7-2、排队延迟"><a href="#5-7-2、排队延迟" class="headerlink" title="5.7.2、排队延迟"></a>5.7.2、排队延迟</h3><p>Def：任务放入任务队列到任务去除所花费的时间</p><p><img src="https://img-blog.csdnimg.cn/5a412966fbe34842b9863ef612b3314f.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h3 id="5-7-3、任务丢弃次数"><a href="#5-7-3、任务丢弃次数" class="headerlink" title="5.7.3、任务丢弃次数"></a>5.7.3、任务丢弃次数</h3><p>Def：队列中新生成的任务数量达到上限时丢失的任务数量</p><p><img src="https://img-blog.csdnimg.cn/2c071aaa262f4169a875a3c5be110a1f.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h3 id="5-7-4、卸载成本"><a href="#5-7-4、卸载成本" class="headerlink" title="5.7.4、卸载成本"></a>5.7.4、卸载成本</h3><p>Def：使用EN所需成本</p><p><img src="https://img-blog.csdnimg.cn/fb64d0f9f142476a812dbce9adc453e4.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h2 id="5-8、计算卸载性能分析"><a href="#5-8、计算卸载性能分析" class="headerlink" title="5.8、计算卸载性能分析"></a>5.8、计算卸载性能分析</h2><p>略</p><h1 id="6、结论"><a href="#6、结论" class="headerlink" title="6、结论"></a>6、结论</h1><p>有待解决：</p><p>在未来，我们将深入研究是否有关于DRL的模型压缩技术，以及如何以细粒度的方式调度基于FL的DRL训练。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/03/14/bian-yuan-ji-suan-xi-tong-xia-ji-yu-shen-du-xue-xi-de-ji-suan-xie-zai-suan-fa/"/>
      <url>/2024/03/14/bian-yuan-ji-suan-xi-tong-xia-ji-yu-shen-du-xue-xi-de-ji-suan-xie-zai-suan-fa/</url>
      
        <content type="html"><![CDATA[<h1 id="1、文章信息："><a href="#1、文章信息：" class="headerlink" title="1、文章信息："></a>1、文章信息：</h1><p>IEEE TRANSACTIONS ON MOBILE COMPUTING，CCF-A</p><h1 id="2、文章概述"><a href="#2、文章概述" class="headerlink" title="2、文章概述"></a>2、文章概述</h1><h2 id="2-1、文章思想"><a href="#2-1、文章思想" class="headerlink" title="2.1、文章思想"></a>2.1、文章思想</h2><p>本文考虑了一个具有AP和多个WD的无线供电MEC网络，如图所示：</p><p><img src="https://img-blog.csdnimg.cn/56ce613c2e0f4c56a87cb5302325eebc.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>每个WD遵循二进制卸载策略（即要么全部卸载要么全部本地执行）。本文的目标是联合优化每个WD的任务卸载决策、WPT（无线供电传输）和任务卸载之间的传输时间分配，以及根据时变的无线信道进行多个WD之间的时间分配。</p><p>基于此，作者提出了一个在线卸载框架（DROO），以最大化所有WD计算速率的加权和（单位时间内处理的比特数）。与现有整数规划和基于学习的方法相比有以下贡献：</p><ul><li>提出的DROO框架学习过去的卸载策略，在时变无线信道条件下自动更改策略。（完全消除了解决MIP问题的必要，避免了随着数据量增多而造成的计算复杂度爆炸）【为什么具有高复杂性】</li><li>与深度学习方法不同，DROO将原始问题分解为卸载策略子问题与资源分配子问题，不需要离散化的信道增益，避免了维数灾难问题</li><li>为了高效地生成卸载动作，设计了一种新颖的保序动作生成方法。具体而言，它只需要从少量候选动作中进行选择，因此在具有高维动作空间的大规模网络中具有计算可行性和高效性。同时，它还提供了生成动作的高多样性，并且比传统的动作生成技术具有更好的收敛性能。</li><li>开发了一种自适应程序，能够动态地调整DROO算法的参数。具体而言，它逐渐减少在一个时间段内需要解决的凸资源分配子问题的数量。这有效地降低了计算复杂度，同时不会影响解决方案的质量。</li></ul><h2 id="2-2、related-work"><a href="#2-2、related-work" class="headerlink" title="2.2、related work"></a>2.2、related work</h2><p>在DQN方法中，作者基于离散化的信道增益作为输入向量，因此在需要高信道量化精度时遭受维数灾难和缓慢收敛。</p><p>此外，在每次迭代过程中的决策穷举性质，DQN不适合处理高维动作。</p><h1 id="3、主体部分"><a href="#3、主体部分" class="headerlink" title="3、主体部分"></a>3、主体部分</h1><h2 id="3-1、系统建模"><a href="#3-1、系统建模" class="headerlink" title="3.1、系统建模"></a>3.1、系统建模</h2><p>1）假设WPT和communication是在同一频段执行，在每个设备处实现TDD（时分复用电路）避免WPT与communication之间相互干扰。</p><p>2）假设信道互逆（即上行链路与下行链路的信道增益是相同的）</p><p>3）系统时间被划分为连续的等长时间帧T（设置为小于信道相干时间（信道保持稳定的最长时间））</p><p><img src="https://img-blog.csdnimg.cn/a725ff0a70974d65b1354498ef0d5413.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>标记的时间帧处AP与第i个WD之间的无线信道增益（用于评估信号传输的质量和通信速率）</p><p><img src="https://img-blog.csdnimg.cn/777c3378940c40bfa524a15c53b6d785.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>用于WPT的时间，a ∈[0,1] ，其中AP广播RF能量以供WD收集</p><p><img src="https://img-blog.csdnimg.cn/87a7f0ca061f47c6b4e913180174f1a9.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>表示第i个WD收获的能量值，其中μ表示能量收集效率，P表示AP发射功率</p><p><img src="https://img-blog.csdnimg.cn/6dc436abc3294382bc57e3ab3f4f24fe.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>第i个WD的权重，权重越大，分配给WD的计算速率越大</p><p><img src="https://img-blog.csdnimg.cn/f25216a32058490db29276553fe73036.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>代表卸载策略，枚举值（0，1），0代表本地执行； 1代表卸载到AP</p><h2 id="3-2、本地计算模型"><a href="#3-2、本地计算模型" class="headerlink" title="3.2、本地计算模型"></a>3.2、本地计算模型</h2><p>本地计算模式下的WD可以同时收集能量和执行计算任务。</p><p><img src="https://img-blog.csdnimg.cn/21417842856d45729fe6384e98455764.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>处理器的计算速度（每秒的周期数）</p><p><img src="https://img-blog.csdnimg.cn/b3d50fdcd2684d91a4ccb0315174579d.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>表示代表计算时间</p><p><img src="https://img-blog.csdnimg.cn/b0dbea4aba894f5581e2337a2707204b.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>本地计算速率（以比特每秒为单位）</p><p>T：等长时间帧，φ表示处理一位任务数据所需的周期数</p><h2 id="3-3、边缘计算模型"><a href="#3-3、边缘计算模型" class="headerlink" title="3.3、边缘计算模型"></a>3.3、边缘计算模型</h2><p>由于TDD约束，处于卸载模式的WD只能在收获能量之后将其任务卸载到AP。</p><p>要下载到WD的计算反馈比卸载到AP的数据短得多，所以完全忽略AP在任务计算和下载上花费的时间。</p><p><img src="https://img-blog.csdnimg.cn/4203861f064d4ccd9a4b280af7977e3a.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>第i个WD的卸载时间，前者取值[0，1]</p><p>为了最大化计算速率，执行任务卸载的WD会耗尽其收获能量来执行任务卸载，则计算速率等于其数据卸载能力：</p><p><img src="https://img-blog.csdnimg.cn/c7ecdd0cb3a144f38c8f2555cfcece1e.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>B代表通信带宽、N代表接收机噪声功率。</p><h2 id="3-4、问题表述"><a href="#3-4、问题表述" class="headerlink" title="3.4、问题表述"></a>3.4、问题表述</h2><p>在标记的时间帧中无线供电MEC网络的加权和计算速率被表示为：</p><p><img src="https://img-blog.csdnimg.cn/ab099283a1b24790b9823a7f16d5bf50.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>则本文目的便是：</p><p><img src="https://img-blog.csdnimg.cn/4650aa37608346d18bbc7b4c4e6a88fc.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>可见P1是一个混合整数规划非凸问题，但是一旦给定x，则P1可以简化为以下凸问题：</p><p><img src="https://img-blog.csdnimg.cn/ae2caaecf9d243e6a4d3e25e8015d65c.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>则将问题P1分解为两个子问题：</p><ol><li>卸载决策：需要在2的N次方个可能的卸载决策中搜索到较好的卸载决策x</li><li>资源分配：关于凸问题P2的最优时间分配可以高效解决，例如，在相关对偶变量上使用一位二分搜索，其时间复杂度在O（N）内</li></ol><h1 id="4、DROO算法"><a href="#4、DROO算法" class="headerlink" title="4、DROO算法"></a>4、DROO算法</h1><p><img src="https://img-blog.csdnimg.cn/40b45a40bf3045fe90ee1bf9d907cade.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h2 id="4-1、算法概述"><a href="#4-1、算法概述" class="headerlink" title="4.1、算法概述"></a>4.1、算法概述</h2><p>旨在设计一个卸载策略函数Π，一旦在每个时间帧的开始给定信道增益h，就可以快速生成一个最优卸载策略x</p><p><img src="https://img-blog.csdnimg.cn/7508594214574673b04f94835087f9d1.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>所提出的DROO算法会从经验中逐渐学习这样的策略函数Π</p><p> <img src="https://img-blog.csdnimg.cn/475a815d191a4817b3e37151a8544fa5.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>算法结构图如图所示，由交替的两阶段组成：Offloading Action Generation 和 Offloading Policy Update</p><p>卸载动作的生成是基于DNN的使用，该DNN将信道增益h作为输入，基于卸载策略Π（由θ参数化）输出卸载动作x</p><p>猜测：使用DNN生成卸载策略，然后将卸载策略量化为K个离散的卸载决策选项，使用二进制编码表示每个选项的状态。 然后选取所选动作致使P2问题最大化的x，基于input的h组成训练样本加入经验回访池中。</p><p>卸载策略更新：从经验回放池中随机选取batch个随机样本训练DNN，DNN将其参数更新。以此类推以更新策略</p><h2 id="4-2、Offloading-Action-Generation（没看懂）"><a href="#4-2、Offloading-Action-Generation（没看懂）" class="headerlink" title="4.2、Offloading Action Generation（没看懂）"></a>4.2、Offloading Action Generation（没看懂）</h2><p>在第一个时间帧时，DNN的参数θ被随机初始化（零均值正态分布）。</p><ul><li>那么DNN首先输出一个宽松计算卸载动作x，该动作是由参数化函数表示的</li></ul><p>逼近定理：如果在神经元处应用适当的激活函数，则具有足够隐藏神经元的一个隐藏层足以逼近任何函数映射f</p><ul><li>通过量化函数将DNN输出的动作x量化为K个二进制卸载动作（K是一个设计参数），量化函数gk如下：</li></ul><p><img src="https://img-blog.csdnimg.cn/d07d857aaacc453a9e65efa86e7423e0.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><p>此处，K可以是1到2的N次方中的任意整数，越大的K可以获得越好的解质量但是会有更大的计算复杂度，这里作者提出了一种保序量化方法用来平衡质量与复杂度之间的关系。</p><p>其基本思想是：量化期间保持排序。</p><h2 id="4-3、卸载策略更新"><a href="#4-3、卸载策略更新" class="headerlink" title="4.3、卸载策略更新"></a>4.3、卸载策略更新</h2><p>此处使用经验重放技术</p><p>（参考文献如下：（可重用）</p><p>Human-level control through deep reinforce-ment learning</p><p>Reinforcement learning for robots using neuralnetworks）</p><p>DNN的参数使用Adam算法来更新，以减少平均交叉熵损失</p><p>DNN迭代的从最佳状态动作对中学习，随着时间推移产生更好的状态动作对。同时在有限存储器空间约束情况下（状态动作对会不断使用FIFO策略更新），DNN仅从最近最优生成的的数据样本中学习。这种闭环强化学习机制不断改进其卸载策略，直到收敛。</p><p><img src="https://img-blog.csdnimg.cn/f70fc5a93b944dc5a91c46903113a902.png" alt="img"><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">编辑</p><h2 id="4-4、K的自适应设置"><a href="#4-4、K的自适应设置" class="headerlink" title="4.4、K的自适应设置"></a>4.4、K的自适应设置</h2><p>DROO算法设计的优势在于其消除了求解困难MIP问题的需要，从而降低了计算复杂度。在该算法中其主要计算复杂度在于求解P2问题以获取K个动作中最佳卸载动作。</p><p>这里越大的K会导致在每个时间帧中更好的卸载决策，也因此会有更好的卸载策略，所以设置K的时候会有一个基本的计算复杂度——性能之间的权衡。</p><p>作者提出了一个自适应过程，自动调整由保序量化方法产生的量化动作的数量。</p><p>（未细看）</p><h1 id="5、实验结果"><a href="#5、实验结果" class="headerlink" title="5、实验结果"></a>5、实验结果</h1><h2 id="5-1、收敛性能"><a href="#5-1、收敛性能" class="headerlink" title="5.1、收敛性能"></a>5.1、收敛性能</h2><h2 id="5-2、更新间隔的影响"><a href="#5-2、更新间隔的影响" class="headerlink" title="5.2、更新间隔的影响"></a>5.2、更新间隔的影响</h2><h2 id="5-3、计算速率性能"><a href="#5-3、计算速率性能" class="headerlink" title="5.3、计算速率性能"></a>5.3、计算速率性能</h2><h2 id="5-4、执行延迟"><a href="#5-4、执行延迟" class="headerlink" title="5.4、执行延迟"></a>5.4、执行延迟</h2><h1 id="6、结论"><a href="#6、结论" class="headerlink" title="6、结论"></a>6、结论</h1><p>本文中作者基于深度强化学习提出了在线卸载算法DROO，以最大限度地提高无线供电MEC网络中的加权和计算率与二进制计算卸载。该算法从过去卸载经验中学习，通过强化学习改善其由DNN产生的卸载行为。并通过保序量化方法和自适应参数设置方法加速算法收敛。其提出的方法与传统方法相比，避免了解决MIP问题的需要，仿真结果表明DROO实现了接近最优的性能（和现有的基准方法相比），但却减少了CPU执行延迟超过一个数量级，使得在无线衰落环境中无线供电MEC系统的实时性变得真正可行。</p><p>本文的挑战在于，该DROO框架适用于一般MEC网络，当对象是移动的WD时将会导致DROO更难收敛。猜测原因在于WD的移动性造成信号不稳定、影响卸载到服务器的时间？</p><p>未来笔者希望DROO可以用来解决设计耦合整数决策和连续资源分配问题的无线通信和网络中的各种MIP问题，例如，D2D通信中的模式选择、蜂窝系统中的用户到基站关联、无线传感器网络中的路由以及无线网络中的缓存放置。</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
